<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<title>Raesene's Ramblings</title>
	
	<meta name="author" content="raesene">

	<!-- Enable responsive viewport -->
	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
	<!--[if lt IE 9]>
	<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->

	<!-- Le styles -->
	<link href="https://raesene.github.io/assets/resources/bootstrap/css/bootstrap.min.css" rel="stylesheet">
	<link href="https://raesene.github.io/assets/resources/font-awesome/css/font-awesome.min.css" rel="stylesheet">
	<link href="https://raesene.github.io/assets/resources/syntax/syntax.css" rel="stylesheet">
	<link href="https://raesene.github.io/assets/css/style.css" rel="stylesheet">

	<!-- Le fav and touch icons -->
	<!-- Update these with your own images
	<link rel="shortcut icon" href="images/favicon.ico">
	<link rel="apple-touch-icon" href="images/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
	-->

	<link rel="alternate" type="application/rss+xml" title="" href="https://raesene.github.io/feed.xml">
</head>

<body>
	<nav class="navbar navbar-default visible-xs" role="navigation">
		<!-- Brand and toggle get grouped for better mobile display -->
		<div class="navbar-header">
			<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
				<span class="sr-only">Toggle navigation</span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			</button>
			
			<a type="button" class="navbar-toggle nav-link" href="https://github.com/raesene">
				<i class="fa fa-github"></i>
			</a>
			
			
			<a type="button" class="navbar-toggle nav-link" href="https://twitter.com/raesene">
				<i class="fa fa-twitter"></i>
			</a>
			
			
			<a type="button" class="navbar-toggle nav-link" href="mailto:raesene@gmail.com">
				<i class="fa fa-envelope"></i>
			</a>
			
			<a class="navbar-brand" href="https://raesene.github.io/">
				<img src="https://www.gravatar.com/avatar/8c189c784a607c4b5d52b0c7ee69b036?s=35" class="img-circle" />
				Raesene's Ramblings
			</a>
		</div>

		<!-- Collect the nav links, forms, and other content for toggling -->
		<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
			<ul class="nav navbar-nav">
				<li class="active"><a href="https://raesene.github.io/">Home</a></li>
				<li><a href="https://raesene.github.io/categories/index.html">Categories</a></li>
				<li><a href="https://raesene.github.io/tags/index.html">Tags</a></li>
			</ul>
		</div><!-- /.navbar-collapse -->
	</nav>

	<!-- nav-menu-dropdown -->
	<div class="btn-group hidden-xs" id="nav-menu">
		<button type="button" class="btn btn-default dropdown-toggle" data-toggle="dropdown">
			<i class="fa fa-bars"></i>
		</button>
		<ul class="dropdown-menu" role="menu">
			<li><a href="https://raesene.github.io/"><i class="fa fa-home"></i>Home</a></li>
			<li><a href="https://raesene.github.io/categories/index.html"><i class="fa fa-folder"></i>Categories</a></li>
			<li><a href="https://raesene.github.io/tags/index.html"><i class="fa fa-tags"></i>Tags</a></li>
			<li class="divider"></li>
			<li><a href="#"><i class="fa fa-arrow-up"></i>Top of Page</a></li>
		</ul>
	</div>

	<div class="col-sm-3 sidebar hidden-xs">
		<!-- sidebar.html -->
<header class="sidebar-header" role="banner">
	<a href="https://raesene.github.io/">
		<img src="https://www.gravatar.com/avatar/8c189c784a607c4b5d52b0c7ee69b036?s=150" class="img-circle" />
	</a>
	<h3 class="title">
        <a href="https://raesene.github.io/">Raesene's Ramblings</a>
    </h3>
</header>


<div id="bio" class="text-center">
	Security Geek, Kubernetes, Docker, Ruby, Hillwalking
</div>


<div id="contact-list" class="text-center">
	<ul class="list-unstyled list-inline">
		
		<li>
			<a class="btn btn-default btn-sm" href="https://github.com/raesene">
				<i class="fa fa-github-alt fa-lg"></i>
			</a>
		</li>
		
		
		<li>
			<a class="btn btn-default btn-sm" href="https://twitter.com/raesene">
				<i class="fa fa-twitter fa-lg"></i>
			</a>
		</li>
		
		
		<li>
			<a class="btn btn-default btn-sm" href="mailto:raesene@gmail.com">
				<i class="fa fa-envelope fa-lg"></i>
			</a>
		</li>
		
	</ul>
	<ul id="contact-list-secondary" class="list-unstyled list-inline">
		
		
		<li>
			<a class="btn btn-default btn-sm" href="https://linkedin.com/in/rorym">
				<i class="fa fa-linkedin fa-lg"></i>
			</a>
		</li>
		
		<li>
			<a class="btn btn-default btn-sm" href="https://raesene.github.io/feed.xml">
				<i class="fa fa-rss fa-lg"></i>
			</a>
		</li>
	</ul>
</div>
<!-- sidebar.html end -->

	</div>

	<div class="col-sm-9 col-sm-offset-3">
		<div class="page-header">
  <h1>Raesene's Ramblings </h1>
</div>



<article class="home">

  <span class="post-date">
    
    March
    25th,
    
    2009
  </span>

  <h2>
    <a href="https://raesene.github.io/blog/2009/03/25/thoughts_on_sec/">Thoughts on Secure Data Handling in web applications...</a>
  </h2>

  <div>
    
    
    <p>I had an interesting conversation/debate over on <a href="http://www.reddit.com/r/programming/comments/86kgp/xss_cross_site_scripting_prevention_cheat_sheet/c08g0ol?context=3">reddit</a> today on the topic of input handling and I thought it was worth posting up.<br />
Essentially there are two approaches handling data in an web applications.<br />
1. Carry out input validation as the data enters your application.  This can either be white-list (only allow "known good" data types), or black-list (try to block "known-bad" data types)<br />
2.  Carry out output normalization on the data as it leaves your application.  Here you look to understand the special or "meta" characters for the type of system or data format that you are outputting to and ensure that the data is encoded or rendered in such a way that it can't have a negative effect on that output system.<br />
So which of these approaches is better?  Well my view on that after my discussion is that they both have pros and cons, which need to be considered before making a choice.<br />
<u><strong><big>Input Validation</big></strong></u></p>
<p><b>Pros:</b> The advantage of white list input validation is that, in a lot of cases, you can relatively easily cut down the number of attacks that will be effective against an application with minimal effort.  For example if you're not taking in mark-up (eg, HTML) in any part of your application then stripping or blocking the &lt; and &gt; characters from your input will drastically reduce your exposure to Cross Site Scripting.  This is the approach that .NET request validation takes.</p>
<p><b>Cons:</b>The problem with input validation is, it can never take account of all possibilities.  It's impossible to know when you take input into the application, how that data will be used and exactly where it will be processed in future, so there's always a risk that it will miss some class of character which turns out to be important to a given format</p>
<p><u><strong><big>Output Normalization</big></strong></u></p>
<p><b>Pros: </b>So essentially the opposite applies.  The advantage of output normalization is that it can take into consideration the exact nature of the system that the data is being passed to and can ensure that the data it's passing will not have a negative effect.  This kind of approach can be seen in HTML encoding function like h() in Ruby on Rails.</p>
<p><b>Cons: </b>Essentially for me the major downside here is a practical one.  A security control that needs to be implemented many times to be effective is one that is likely to be forgotten and because under ordinary conditions the application is likely to behave perfectly even though the control isn't in place, a developer may well not notice the problem until it's too late.  You can see this kind of effect in a lot of web applications.  I've seen many cases where the obvious areas of the application (form fields) have been covered for things like Cross Site Scripting, but more obscure areas (drop-downs, cookies, HTTP headers) get missed out, either because the developer forgets, or because they don't realise that those areas of the application are susceptible to attack</p>
<p>So which of these approaches would I recommend..... Well I'm a security person, so I'll say <b><i>Both</i></b> for defence in depth!<br />
Beyond that I'd say that Input validation is a great first step and will cut down the practical attacks greatly, but if you're looking for a "perfect" approach then you'll need to add output normalization to the mix...</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    March
    8th,
    
    2009
  </span>

  <h2>
    <a href="https://raesene.github.io/blog/2009/03/08/xss_in_rails/">XSS in Rails Applications</a>
  </h2>

  <div>
    
    
    <p>I'm doing some research at the moment for a presentation I'm doing for the <a href="http://www.scotlandonrails.com/">Scotland on Rails</a> conference, later this month.  As part of that I've been downloading some sample Rails applications to get an idea of common security issues that I can discuss.<br />
Interestingly on popular applications that I've downloaded so far, I'm 2 for 2 on the exact same problem.<br />
Both of them have XSS vulnerabilities from the user--&gt;admin sides of the site.  So the end-user pages have output encoding to restrict XSS but the admin sections don't consistently provide the same protection.<br />
It's also interesting that both applications seem to be relying on output encoding as a defence as opposed to input validation.  In my experience the best defence is a combination of the two...<br />
Of course that leads to some potentially nasty exploits around stealing admin credentials from the site in question.  Hey looks like I'll have some stuff to talk about anyway :)</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    December
    22nd,
    
    2008
  </span>

  <h2>
    <a href="https://raesene.github.io/blog/2008/12/22/penetration_tes/">Penetration Test Scoping</a>
  </h2>

  <div>
    
    
    <p>Got a reminder I've not blogged in a while, so here's the next part of what I was going to talk about..<br />
So, following on from my <a href="http://www.mccune.org.uk/blog/000508.html">first post</a> in this series I thought I'd go on to talk about penetration test scoping.<br />
Getting the scope right is one of the most important parts of a successful pen. test.  If you get the wrong scope it won't matter how brilliantly the test is executed or how great the report looks, because you won't have fulfilled the customers requirements.<br />
Unfortunately in a lot of cases the customer doesn't actually know what they want, they may have heard that they need "one of those security test things", they may have auditors telling them they have to have one, or if you're lucky they may have an idea of what they're looking to achieve.<br />
The best pen. tests have specific goals in mind, which allow specific tests to be scoped.  Most commonly a good scope will focus on the question "what's changed", along with a view of the level of security desirable for an application.<br />
So a high risk new application on a new platform is likely to warrant a fairly heavy review (web application, possibly code review, likely config. security review of the operating system and other new components like firewalls or routers), whereas some new pages added to an existing application where it's purely static content, might not warrant a review at all (or a very quick sense check).<br />
Ultimately there's going to be a trade-off between time spent and the level of assurance over security that's needed.  A full code-review/manual build review/architecture review of a new application is likely to provide the best level of assurance, but at a pretty high cost.  A "black box" vulnerability scan and web application test, will likely be quick and therefore cheaper, but will provide a lower level of assurance.<br />
next time (hopefully sooner) I'll talk about some of the challenges in executing tests and touch on some of the gotchas that can cause problems</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    December
    14th,
    
    2008
  </span>

  <h2>
    <a href="https://raesene.github.io/blog/2008/12/14/what_is_penetra/">What is Penetration Testing?</a>
  </h2>

  <div>
    
    
    <p>I'm planning to do a series of posts about penetration testing over the next couple of weeks so I thought I should start in the obvious place of defining what it actually is.<br />
You'd think this would be relatively straightforward, but the term "penetration testing" is mis-used all over the place.  Some people use it to refer to vulnerability assessment, some people use it to refer to Web Application Security Assessment, and a lot of business people use it to refer generically to any and all security assessment activity.<br />
So what actually is it?  Well for me, a penetration test is a scenario based assessment where the tester will actually try to exploit security vulnerabilities in a system or systems (depending on the scope) and then leverage those exploited vulnerabilities to gain further access to systems within the scope of the assessment which may be accessible after exploiting the initial vulnerability.<br />
So that's what it is, why is it important to use the term correctly?<br />
Well, different security assessment types have different characteristics and provide the owner of the system with different levels of assurance, so it's important to make sure everyone's talking about the same thing.<br />
For example, vulnerability assessment is typically primarily tool based (eg, Nessus), focuses on networking/Operating System/maybe database level problems and doesn't usually exploit the vulnerabilities found.  Pretty low risk to the systems under test (usually) but won't provide definite confirmation of problems and typically doesn't look at web applications, so it won't cover all the attack surface of a typical web application exposed over the Internet.<br />
So if someone calls a vulnerability assessment a penetration test (and this is pretty common, in my experience) there's a good chance that someone's going to be disappointed in the results...<br />
From the definition I used there's a couple of areas that can be very important to define correctly when conducting a test, so next time, I'm planning to go over some of the common problems and misconceptions in scoping penetration tests.</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    December
    10th,
    
    2008
  </span>

  <h2>
    <a href="https://raesene.github.io/blog/2008/12/10/death_of_pen_te/">Death of Pen Testing?</a>
  </h2>

  <div>
    
    
    <p>http://riskmanagementinsight.com/riskanalysis/?p=532</p>
<p>Very interesting post over at Riskanalysis.is on penetration testing and what it may turn in to.<br />
There's some good reasons to do penetration testing in there and I'd agree that targeted testing to prove or disprove theories about the security environment is a smart way to use penetration testing.  My feeling though is that, at the moment, only more mature security organisations will be in a good place to use it in that way.<br />
For most companies there are other reasons why penetration testing is going to remain on the menu in its current form</p>
<ul>
<li> <b>Compliance.</b>  Penetration testing seems to be getting commonly adopted as one of the "bullet points" that need to be completed to comply with industry or government regulations, probably most noticable by PCI</li>
<li><b>Externally hosted applications.</b>  In situations when a company doesn't have great visibility of an application that they're entrusting valuable data to (eg, most outsourced application hosting setups) they need some way to get comfort that a reasonable level of security is being applied to that application.  Usually that will involve a penetration test, especially if the application is exposed to a hostile envrioment (like the Internet!)</li>
<p>So whilst I'd definitely like to see smarter use of penetration tests, I don't think that testing as it's used currently is going to go out of fashion any time soon.
</ul>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    December
    10th,
    
    2008
  </span>

  <h2>
    <a href="https://raesene.github.io/blog/2008/12/10/catching_out_do/">Catching out dodgy security policies</a>
  </h2>

  <div>
    
    
    <p>Here's a question to ask your security policy people, to see whether their recommendations are actually risk based or just "best guesses"...<br />
"Have you updated the minimum password length/complexity requirements due to recent advances in password cracking speeds?"<br />
I was reading a couple of posts on the Red Database Security blog (<a href="http://blog.red-database-security.com/2008/12/08/md5-bruteforcer-barswf/">here</a> and <a href="http://blog.red-database-security.com/2008/12/07/gsauditor-fastest-oracle-11g-password-cracker-afaik/">here</a>, and it occurred to me that despite the increases that have been made in password cracking speeds over the last couple of years, I've not seen a lot of movement in minimum password length/strength requirements to go along with it...<br />
Obviously password policies should be tailored to mitigate the threats to the systems they protect and the primary risk that long passwords mitigate is an offline attack where the attacker has access to the encrypted password.  (the more common online brute-force is better mitigated by account lockout and security monitoring in most cases)<br />
So if crackers are getting faster, passwords should obviously get longer...</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    September
    6th,
    
    2008
  </span>

  <h2>
    <a href="https://raesene.github.io/blog/2008/09/06/why_ebook_reade/">Why eBook Readers won't succeed for now...</a>
  </h2>

  <div>
    
    
    <p>I really like the idea of eBook readers and I've been following the progress of a number of them for a while now (There's an  excellent resource over at <a href="http://www.mobileread.com">the MobileRead site</a>).<br />
But there's one glaringly obvious reason why they won't succeed for recreational book readers... which is the absurd pricing of eBooks.<br />
The most recent evidence of this is the launch of the Sony reader in the UK.  I had a look round <a href="http://www.sonystyle.co.uk">their site</a> and all looks well.  The price is reasonable (£199) and the product looks nice.  To get a feel for the books available I went to <a href="http://www.waterstones.co.uk"> Waterstones UK website</a>, who are Sonys eBook partner for the launch..<br />
What I found really does surprise me, it's like the book publishers want this to fail.<br />
First book on the page, The Private Patient by P.D James.  Waterstones eBook price <b>£12.92</b>... Amazon.co.uk's price for the Hardback version..... <b>£9.49</b> !<br />
So they're seriously expecting people to pay 36% more for an eBook which is a digital file, easily produced, with no shipping or production costs and with DRM on it, as against a hard back book that could be resold once you've read it.<br />
Looking through some of the other prices, this doesn't appear to be a limited aberration either, the differential is higher for hard back books (a concept which makes zero sense in an eBook world) but the prices seem uniformly higher for eBooks than physical ones.<br />
Now I do see that for some applications where physical books are impractical eBooks , whatever the cost, could make sense.<br />
But for recreational reading, the chances that large numbers of book lovers (many of whom are attached to the experience of physical books anyway) will change for a more expensive, more restrictive, electronic implementation are pretty slim!</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    July
    22nd,
    
    2008
  </span>

  <h2>
    <a href="https://raesene.github.io/blog/2008/07/22/dns_vulnerabili/">DNS vulnerability - are there any other mitigations apart from patching?</a>
  </h2>

  <div>
    
    
    <p>Well as I'm sure everyone is aware the details of the DNS flaw that <a href="http://www.doxpara.com">Dan Kaminsky</a> found have been disseminated round the 'net a bit early.<br />
I'm not going to get into the politics of whether that's a good thing/bad thing or how urgent patching is as it's been done to death elsewhere...<br />
I was thinking though about how it may be possible to mitigate this in other ways than patching...<br />
Having heard the detailed explanation from matasano on the vulnerability,  wouldn't it be possible to mitigate this by changing the behaviour of the authoritative name server..?<br />
If I'm understandning things correctly as the authoritative name server for a domain you'd see a whole load of requests for invalid subdomains to your domain (eg, AAAA.MYDOMAIN.COM AAAB.MYDOMAIN.COM) and usually you just respond with NXDOMAIN.  Now the attacker is relying on you responding NXDOMAIN so he can respond with the additional RR of your real website, say, WWW.MYDOMAIN.COM.<br />
Would it be possible to change your behaviour to respond as the attacker would do with the RR for your valid hosts, so causing the caching DNS server to cache them on the first attempt and preventing the attacker from getting the incorrect entries in first..?  The attacker is relying on guessing port and transaction ID so won't get there in the first attempt, so it would seem that this would potentially mitigate the problem..<br />
That said I'm no DNS expert so this may well be off base...</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    July
    1st,
    
    2008
  </span>

  <h2>
    <a href="https://raesene.github.io/blog/2008/07/01/more_virtualiza/">More virtualization fun..</a>
  </h2>

  <div>
    
    
    <p>There's an interesting post at <a href="http://rationalsecurity.typepad.com/blog/2008/06/the-final-front.html">Hoffs blog</a> around virtualization and DMZs and to what level it's "ok" to virtualize a given DMZ environment, following on from a white paper by VMware on the subject<br />
As Hoff mentions you need to understand the wider context in any risk assessment, but I actually think that in the scenarios that VMware have painted out, I'd agree with <a href="http://www.virtualization.info/2008/06/whitepaper-dmz-virtualization-with.html">Alessandro</a>, that the fully collapsed DMZs talked about in the paper are a no-no.<br />
And there's a nice risk assessment reasoning here, it's not just a "ooh hypervisors scary" kind of reaction, honest :) ..<br />
So here's how it works.  In the diagrams they've used they've laid out a picture of a number of security controls.  The main one being separate firewalls segregating the Internet from each of the DMZs in turn.  This would indicate to me that the risk assessment dictated that no one device should be a point of failure for the security being provided by the environment (a more cost effective, but traditionally seen as more risky design would be a single firewall with multiple interfaces, one for each network.)<br />
So if we then introduce virtualization to this scenario then it seems that the option of a "partially collapsed" DMZ meets the security requirements as each DMZ has it's own VMware ESX instance and a compromise of the hypervisor won't result in a breach of DMZ segregation.<br />
I think that in a lot of cases it's easy to look at virtualization as something new but it should be possible to look at the current risk appetite in an environment (are you using separate devices to segregate things, are you relying on VLAN tagging for separation) and then apply that to come up with the appropriate virtualization design.</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    June
    23rd,
    
    2008
  </span>

  <h2>
    <a href="https://raesene.github.io/blog/2008/06/23/avoiding_contro/">Avoiding controls which are "designed to fail"</a>
  </h2>

  <div>
    
    
    <p>One of the great problems and frustrations of working in security is when those darned users don't follow the nice policies that people have spent so much time working on.<br />
But here's the thing, <b>security professionals actually indoctrinate users not to follow policies!</b><br />
How do they do this? Well people like following patterns, and so when the pattern "It's okay not to actually follow this" is established in relation to security , people will apply that pattern the next time they run into a security policy that's potentially difficult or hard to follow.<br />
I'm sure there's a lot of security people saying "No idea what he's talking about, all my policies were made to be followed!"....<br />
O'Rly..<br />
Here's an example that I'll bet is familiar to a lot of people.  Password policy. Does anyone actually follow their companies password policy? I'll bet it looks something like</p>
<ul>
<li>Passwords must be 8 or more characters with upper, lower, numeric and special characters</li>
<li>Passwords must not be based on dictionary words</li>
<li>Passwords must be rotated every 30 days</li>
<li>You must have a different password for every system (including not using the same passwords for personal websites</li>
<li>Oh yeah and once you've got this list of 40 or so random strings that are really tricky to remember and you might not use very often, don't you dare write them down</li>
</ul>
<p>We're setting ourselves up for failure, and study after study shows that users will write down their passwords, or use sequences or many other tricks to make them more memorable.<br />
This example (which may be a users main interaction with "security") sets the expectation that security policies can be ignored, because they're unrealistic.<br />
So what's the answer..<br />
Well when designing controls, I think that it's not enough to just look at the technical security properties in abstract.  We've got to consider the psychological/sociological elements of the people we're expecting to execute the controls, and maybe take a path that isn't the best abstract solution but may well be the one that will work best in real life...<br />
After all once users are set on the path of ignoring security it becomes pretty difficult to get them back on the one true way!</p>

    
    
  </div>

</article>

<hr/>

<ul class="pager"> 

  
  <li class="previous">
    
    <a href="https://raesene.github.io/page15">&larr; Newer</a>
    
  </li>
  
  
  <li>
    <span class="page_number">Page: 16 of 55</span>
  </li>

  
  <li class="next">
    <a href="https://raesene.github.io/page17">Older &rarr;</a>
  </li>
  

</ul>




		<footer>
			<hr/>
			<p>
				&copy; 2022 raesene with Jekyll. Theme: <a href="https://github.com/dbtek/dbyll">dbyll</a> by dbtek.
			</p>
		</footer>
	</div>

	<script type="text/javascript" src="https://raesene.github.io/assets/resources/jquery/jquery.min.js"></script>
	<script type="text/javascript" src="https://raesene.github.io/assets/resources/bootstrap/js/bootstrap.min.js"></script>
	<script type="text/javascript" src="https://raesene.github.io/assets/js/app.js"></script>
</body>
</html>



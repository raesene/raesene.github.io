<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<title>Raesene's Ramblings</title>
	
	<meta name="author" content="raesene">

	<!-- Enable responsive viewport -->
	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
	<!--[if lt IE 9]>
	<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
	<![endif]-->

	<!-- Le styles -->
	<link href="/assets/resources/bootstrap/css/bootstrap.min.css" rel="stylesheet">
	<link href="/assets/resources/font-awesome/css/font-awesome.min.css" rel="stylesheet">
	<link href="/assets/resources/syntax/syntax.css" rel="stylesheet">
	<link href="/assets/css/style.css" rel="stylesheet">

	<!-- Le fav and touch icons -->
	<!-- Update these with your own images
	<link rel="shortcut icon" href="images/favicon.ico">
	<link rel="apple-touch-icon" href="images/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
	-->

	<link rel="alternate" type="application/rss+xml" title="" href="/feed.xml">
</head>

<body>
	<nav class="navbar navbar-default visible-xs" role="navigation">
		<!-- Brand and toggle get grouped for better mobile display -->
		<div class="navbar-header">
			<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
				<span class="sr-only">Toggle navigation</span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			</button>
			
			<a type="button" class="navbar-toggle nav-link" href="https://github.com/raesene">
				<i class="fa fa-github"></i>
			</a>
			
			
			<a type="button" class="navbar-toggle nav-link" href="https://twitter.com/raesene">
				<i class="fa fa-twitter"></i>
			</a>
			
			
			<a type="button" class="navbar-toggle nav-link" href="mailto:raesene@gmail.com">
				<i class="fa fa-envelope"></i>
			</a>
			
			<a class="navbar-brand" href="/">
				<img src="https://www.gravatar.com/avatar/8c189c784a607c4b5d52b0c7ee69b036?s=35" class="img-circle" />
				
			</a>
		</div>

		<!-- Collect the nav links, forms, and other content for toggling -->
		<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
			<ul class="nav navbar-nav">
				<li class="active"><a href="/">Home</a></li>
				<li><a href="/categories/index.html">Categories</a></li>
				<li><a href="/tags/index.html">Tags</a></li>
			</ul>
		</div><!-- /.navbar-collapse -->
	</nav>

	<!-- nav-menu-dropdown -->
	<div class="btn-group hidden-xs" id="nav-menu">
		<button type="button" class="btn btn-default dropdown-toggle" data-toggle="dropdown">
			<i class="fa fa-bars"></i>
		</button>
		<ul class="dropdown-menu" role="menu">
			<li><a href="/"><i class="fa fa-home"></i>Home</a></li>
			<li><a href="/categories/index.html"><i class="fa fa-folder"></i>Categories</a></li>
			<li><a href="/tags/index.html"><i class="fa fa-tags"></i>Tags</a></li>
			<li class="divider"></li>
			<li><a href="#"><i class="fa fa-arrow-up"></i>Top of Page</a></li>
		</ul>
	</div>

	<div class="col-sm-3 sidebar hidden-xs">
		<!-- sidebar.html -->
<header class="sidebar-header" role="banner">
	<a href="/">
		<img src="https://www.gravatar.com/avatar/8c189c784a607c4b5d52b0c7ee69b036?s=150" class="img-circle" />
	</a>
	<h3 class="title">
        <a href="/"></a>
    </h3>
</header>


<div id="bio" class="text-center">
	Security Geek, Penetration Testing, Docker, Ruby, Hillwalking
</div>


<div id="contact-list" class="text-center">
	<ul class="list-unstyled list-inline">
		
		<li>
			<a class="btn btn-default btn-sm" href="https://github.com/raesene">
				<i class="fa fa-github-alt fa-lg"></i>
			</a>
		</li>
		
		
		<li>
			<a class="btn btn-default btn-sm" href="https://twitter.com/raesene">
				<i class="fa fa-twitter fa-lg"></i>
			</a>
		</li>
		
		
		<li>
			<a class="btn btn-default btn-sm" href="mailto:raesene@gmail.com">
				<i class="fa fa-envelope fa-lg"></i>
			</a>
		</li>
		
	</ul>
	<ul id="contact-list-secondary" class="list-unstyled list-inline">
		
		
		<li>
			<a class="btn btn-default btn-sm" href="https://linkedin.com/in/rorym">
				<i class="fa fa-linkedin fa-lg"></i>
			</a>
		</li>
		
		<li>
			<a class="btn btn-default btn-sm" href="/feed.xml">
				<i class="fa fa-rss fa-lg"></i>
			</a>
		</li>
	</ul>
</div>
<!-- sidebar.html end -->

	</div>

	<div class="col-sm-9 col-sm-offset-3">
		<div class="page-header">
  <h1>Raesene's Ramblings </h1>
</div>



<article class="home">

  <span class="post-date">
    
    April
    17th,
    
    2014
  </span>

  <h2>
    <a href="/blog/2014/04/17/changing-times-the-end-of-autocomplete-equals-off/">Changing Times - The end of Autocomplete='off'</a>
  </h2>

  <div>
    
    
    <p>For a long time the subject of browser password storage has been a relatively contentious topic in the Information Security world.</p>


    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    April
    10th,
    
    2014
  </span>

  <h2>
    <a href="/blog/2014/04/10/open-source-responsibility/">Open Source Responsibility</a>
  </h2>

  <div>
    
    
    <p>Unless you’ve been living under a rock for the last couple of days you will have noticed a bit of a kerfuffle about a vulnerability in OpenSSL.  One of the more notable parts of this story has been the wide variety of large companies who have been seriously affected by the problem.</p>


    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    April
    1st,
    
    2014
  </span>

  <h2>
    <a href="/blog/2014/04/01/house-of-cards/">House of Cards</a>
  </h2>

  <div>
    
    
    <p>I was reading <a href="http://www.ramshackleglam.com/2014/04/01/my-website-was-stolen-by-a-hacker-and-i-got-it-back/">this post</a> and I was thinking that this is another good example of the general theme in a lot of modern business and security.</p>

<p>People will a lot of times neglect some of the “plumbing” of their website and not realise quite how important it is to their sites security.  In the linked example it was DNS.  An attacker was able to get control of the site domain name and then essentially controlled the site. That’s one way of pulling it off but there are others.</p>

<p>Good examples of services which are often overlooked but are critical</p>

<ul>
  <li>Hosting services.  If you use VPS or the like and the hosting service is compromised then, the attackers can likely get access to your servers too.  A good example of this was the Linode hack in 2013.  There the attackers didn’t even have Linode as a primary target, they were after one specific customer.</li>
  <li>DNS providers.  If the attacker can control your DNS, they can redirect mail, carry out MITM attacks on web sites, basically make a right mess of your system.  But hacks on DNS providers (either social engineering or direct) are a common theme in stories of compromise.</li>
  <li>E-Mail providers.  Might not seem as critical, but how are most password resets done…. by E-Mail.  If the attacker owns your e-mail service they can usually trigger password resets for other things like DNS or hosting.</li>
</ul>

<p>So what makes me say these things are “neglected”?  Well look at the market and it’s pretty obvious.  In a lot of cases the successful providers in these areas are the cheapest/easiest to use, not the most secure.  Of course there’s the usual security problem of a “market for lemons” in that all providers will say that they’re secure but I’d still recommend that if you have a system that’s important to you (and that’s true for an increasing number of companies who do business primarily on-line), then spending some time trying to find high quality “plumbing” will pay off in the long run.</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    March
    14th,
    
    2014
  </span>

  <h2>
    <a href="/blog/2014/03/14/why-security-is-getting-worse/">Why security is getting worse</a>
  </h2>

  <div>
    
    
    <p>I was doing a talk for the OWASP meeting in Glasgow the other day, which covered the OWASP Top 10.  I had made the point that the Top 10 is largely the same now (in it’s 2013 iteration) as it was in it’s original iteration in 2003. Someone asked me a question based on that which (roughly) was “Why isn’t security getting better?”</p>


    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    March
    6th,
    
    2014
  </span>

  <h2>
    <a href="/blog/2014/03/06/a-rambling-introduction/">A Rambling Introduction</a>
  </h2>

  <div>
    
    
    <p>So herein is a new post on a new system that I may or may not keep up to date, like so many other venues.</p>


    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    June
    2nd,
    
    2013
  </span>

  <h2>
    <a href="/blog/2013/06/02/of-human-stupidity/">Of Human Stupidity</a>
  </h2>

  <div>
    
    
    <p>For a number of years, I have felt that tech companies must be seriously lacking in acumen to take the policies they do with regard to their customers.   Yesterday I noticed however that it is not restricted to tech companies, and it makes an interesting study in human stupidity to see this in operation.</p>
<p>So for example, a search for property management companies in the UK came up with this</p>
<p><a href="http://www.reviewcentre.com/reviews117367.html">http://www.reviewcentre.com/reviews117367.html</a></p>
<p>I have no personal knowledge of the company involved, or whether the reviews in question are in fact accurate,  but I find it inconceivable that any commercial entity would allow their customer service (or their marketing department) to be so egregiously bad as to have that kind of review show up in search engines.  I mean surely they must realize that in the modern world, potential customers are going to look for reviews – and that it is not going to be a positive thing if you have a consistent 1 star rating.</p>
<p>But then I got to comparing it to the behaviour of tech companies – and I am afraid that three immediately jump to mind.  I used to administer Lotus (heard of them?) technologies.  At one point they had a massive chunk of the Office Suite, email, collaborative website and instant messaging market.  Then they were bought by IBM and everything went downhill from there.  There is no doubt in my mind that Domino was a superior product to early versions of Exchange.  Equally QuickPlace was there before SharePoint was really more than a twinkle in Microsoft’s eye.  I see that support was recently finally dropped for Lotus SmartSuite – but in its day it was way ahead of MS Office.</p>
<p>The same can be said of Novell Netware.  I loved that product back when, and I would defend NDS as a better directory service to AD until about ten years ago.  Today who under the age of 30 has even heard of Novell?  And AD runs most of the world's internal networks.</p>
<p>One final example….  Sadly I think Blackberry is going the same way.   Considering that they have been relegated to fourth place in the mobile market, I think it unlikely that they will still be in the race (as an independent company) in a year’s time.  And yet not so long ago they had the vast majority of the smartphone market.</p>
<p>And the common factor in all of this….   Intellectual arrogance and the complete inability or unwillingness to listen to their customer base, or in any way to acknowledge that their product was not automatically superior just because it was the current market leader.</p>
<p>So two things I would take from this…..  Firstly if I were a property management company I would seriously do something about my customer service before I allowed a simple Internet search to make me look that bad.  Secondly, I would bet a lot of money against the tech press who are writing Microsoft off as a major force compared to Apple and Google.  Consistently over the last 20 years they appear to have been the only company who genuinely care about customer service, and also one of the few who try to adapt to changing times.    They have never made any claims about 'doing no evil' - but it consistently appears that caring for your customers on a day to day basis, and being seen to do so, makes good commercial sense.</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    May
    23rd,
    
    2013
  </span>

  <h2>
    <a href="/blog/2013/05/23/windows-azure-backup/">Windows Azure Backup</a>
  </h2>

  <div>
    
    
    <p>I just configured the preview version of Windows Azure Backup.  It is very nice looking and easy to use once you get it up and running - but the instructions to install it are difficult to find and a bit patchy.</p>
<p>First you have to create a certificate for your vault.  You use a utility called makecert.exe which is part of the Windows SDK (the link in the documentation to TechNet doesn't work - so you can get it here.</p>
<p><a href="http://msdn.microsoft.com/en-US/windows/desktop/aa904949">http://msdn.microsoft.com/en-US/windows/desktop/aa904949</a></p>
<p>For reasons that are not clear to me the utility doesn't seem to be available as a standalone - but downloading just the tools part of the SDK contains it.</p>
<p>Then the documentation that actually works is here (there are several wrong versions in different places dotted across their sites).</p>
<p><a href="http://msdn.microsoft.com/en-us/library/windowsazure/dn169036.aspx">http://msdn.microsoft.com/en-us/library/windowsazure/dn169036.aspx</a></p>
<p>The key thing is to follow the instructions exactly - you need <strong>both </strong>the .cer file and the .pfx file (the public and private keys).</p>
<p>Once you have followed all the instructions and configured your vault you can go ahead with the local software install.  If you have had the Beta version of the agent installed, you need to uninstall it and then install the new one.  Once the software is installed and the agent started, you can then register your server - this took a few minutes to do on my machine - so be patient with it.</p>
<p>Once all this is done - configuring your backup and restores is a snip.  I hope that when it comes out of preview the documentation is improved a bit.</p>
<p>&nbsp;</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    May
    18th,
    
    2013
  </span>

  <h2>
    <a href="/blog/2013/05/18/your-framework-will-fail-you-part-2-network-controls/">Your Framework Will Fail You - Part 2 - Network Controls</a>
  </h2>

  <div>
    
    
    <p>This post is part of a series based on a presentation I did for the Scottish Ruby Conference in May 2013 (part 1 <a title="Scottish Ruby Conference Talk – Your Framework Will Fail You" href="http://blog.scotsts.com/?p=630">here</a>) which was around defense in depth and some of the controls companies should be looking at to help protect them when something goes wrong.</p>
<p>The first segment to cover is Firewalling. Network firewalls get quite a bit of flack in the security world, mainly because people tend to rely too heavily on them for protection without really understanding where they are and are not useful.</p>
<p>The "low-risk" setup option that I covered is around the use of egress filtering on firewalls.</p>
<p>One of the main limitations that I see on practical firewall deployments is that they don't take a "default deny" position for all interfaces. In the typical Internet facing firewall setup almost every one will have a default deny rule from the untrusted network (e.g. the Internet), to the more trusted network (e.g. An internal network) but in many cases the other direction (from internal to Internet) will have a default allow rule set-up.</p>
<p>Setting a default deny on connections from trusted--&gt;untrusted networks can be a really useful control in making an attackers life more difficult for them and hindering their post exploitation activities. So in an e-commerce environment it might be possible to have rules on the firewall that restrict all servers from initiating any connections to the Internet except for a couple of hosts for package updates. This means that someone who has access to the server and who trys to connect to any other system on the Internet will get blocked.</p>
<p>If you consider an attack on a web application, once the attacker has compromised a server (e.g. via SQL Injection or command injection) one of the first things they might try to do is make a connection back to a system under their control to download more tools and also to make a shell connection to the compromised system. So with egress filtering this could be considerably trickier to pull off.</p>
<p>One thing if you do intend to do this is, I would recommend putting it in place when you're designing the network. Retro-fitting more restrictive firewall rules can be quite difficult as things like periodic connections that only happen once a month might not be noticed, leading to unexpected failures after the firewall rules have been put in place.</p>
<p>The "high risk" setup option looking at the area of network segregation. One of the setups I've seen quite commonly is that only one firewall is used, with all Internet facing systems in a single DMZ and then potentially all back-end systems on either the Internal network or perhaps in another single DMZ network. It's a setup I call the "warm smarty" approach to security crunchy on the outside but soft and gooey once you get past the shell.</p>
<p>The problem with this approach is that once an attacker has compromised a single server it's much easier for them to attack other systems in the environment and expand their access. The reality is that most internal networks are pretty easy for a dedicated attacker to compromise as there's always some system that doesn't get patched somewhere, so once they're in, it's pretty much game over.</p>
<p>Addressing this isn't cheap or easy but effective network segmentation can make attackers lives much more difficult.</p>
<p>There are a variety of approaches that can be used for network segmentation. One is to segment individual Internet facing applications so that they are in their own DMZ, this can reduce the risk of onwards compromise, although it does depend on the firewall ruleset being suitably restrictive.</p>
<p>This approach obviously will increase management costs, for example requiring more management servers and potentially less automation of maintenance, so there is a trade-off between the desired level of security and the cost involved, but it's something that should be considered rather than just going for the default one firewall approach.</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    May
    13th,
    
    2013
  </span>

  <h2>
    <a href="/blog/2013/05/13/scottish-ruby-conference-talk-your-framework-will-fail-you/">Scottish Ruby Conference Talk - Your Framework Will Fail You</a>
  </h2>

  <div>
    
    
    <p>I was presenting yesterday at the <a title="Scottish Ruby Conference" href="http://2013.scottishrubyconference.com/">Scottish Ruby Conference</a>, and given that the talk is relatively high-level as it covers a lot of ground, I thought it would be a good idea to do a series of blog posts to provide some more details and resources (link to the presentation <a title="Prezi - Your framework will fail you" href="http://prezi.com/c3d2qpsxgcdv/your-framework-will-fail-you/">here</a>.)</p>
<p>The title of my talk was "Your framework will fail you". I had the idea for it when reading about some of the security bugs in Rails came up earlier in the year and led my to think some more about defence in depth. Anyone in security will know this as one of those things that we think is a good idea but which can be a bit of a hard sell as when someone pays for a security control (e.g. Anti-Virus, Firewall) it can be tricky to say "yep that will fail sometimes so we need to buy some other things as well".</p>
<p>However if anything has been proven by the increase in public vulnerabilities, exploits and compromises, it is that all security controls fail and you will be well served by having a fall-back control or detective control to notice when the main one has failed.</p>
<p>The way I structured the presentation was in two halves. The first looks at the important topics of threat modelling (e.g. who's going to attack you) and a bit about why defence in depth is important. After that it looks at various layers of a solution and talk about controls for a low-risk/budget scenario and a high-risk/budget one. The focus on the low risk option was to look at controls which can be put in easily/cheaply. They may not be super-effective all the time, but they have their uses. On the high-risk end I looked at things which can provide more protection but will take more resource to manage, alternative in some cases it's the same control as the low-risk version but with more time dedicated to managing it (e.g. a lot of the detective controls are only really good if well managed).</p>
<p>The blog posts will be coming out every other day or so looking at the solution layers and hopefully I'll get to the end of the series without interruption :)</p>

    
    
  </div>

</article>


<article class="home">

  <span class="post-date">
    
    May
    6th,
    
    2013
  </span>

  <h2>
    <a href="/blog/2013/05/06/performing-a-diy-security-review-workshop-at-bsides-london/">"Performing a DIY Security Review" Workshop at BSides London</a>
  </h2>

  <div>
    
    
    <p>We had a great time doing our workshop at BSides London recently.  In fact we had a great time in general - the conference was lots of fun.</p>
<p>This was the first long(ish) workshop I had ever prepared for a conference, and I was surprised at how much work was involved in it (compared to an ordinary presentation).  We not only had to create the presentation, but build the infrastructure, create Kali builds on USB sticks, set up the demos, prepare a worksheet for the participants and prepare the two 'test reports' I had promised in the description of the workshop.  Then we had to test, test, test in an attempt to appease the dark god of demos!</p>
<p>We were coming down from Scotland to London for the event and quickly discovered a major drawback - we had a lot of kit....   We needed two PC laptops to be the Nessus Servers and host the vms for the demos.  We also had a Surface Pro for running the demo, a Surface RT (just for kicks) and a MacBook Air to run Rory's presentation.  Add in a switch and cables (because we didn't like the idea of trying to run eight sets of Nessus scans over wireless) plus a fourway and sundry hardprint materials for the participants and we had three huge rucksacks full of stuff.  Going down the stairs at the station I was scared I was going to tip over backwards.</p>
<p>Anyway after a brief panic when we thought the five hundred bottle openers we had ordered for the conference swagbags had not turned up, we found them and then got set up.  We were a bit nervous that after all the effort, no one would be interested.  When I checked the subscription sheet, we had ten signups for 8 slots (the room was on the small side).  And then people started to turn up - and there were loads more than on the sheet.  Unfortunately, we did not have room to let everyone participate in the demos, but we managed to fit everyone (16 people!) into the room although it was a bit on the hot and crowded side.</p>
<p>So the purpose of the workshop was to show people who were technical, but not professional testers, to prepare for a review by eliminating all easily correctable faults in advance of the test.  This would enable the tester to focus on serious issues rather than finding and documenting things such as missing patches and SSLv2.  The example given was of the imaginary UWC company - and we showed off two mock reports an 'before' with 58 vulnerabilities, and an 'after' with 6.  The 'sting' was supposed to be that amongst the six - was a critical SQL vulnerability which the tester had not had time to investigate in the first scenario, but found in the second.</p>
<p>We did four demos:- nmap, Nessus, and two Metasploits.  The second Metasploit was the classic which really impressed me when I started testing - using an unpatched workstation to steal an Admin's token and use it to add a user to the Domain Admins group on a fully patched DC.  The dark god did not really visit us - and everyone seemed to get on well.</p>
<p>We hope everyone enjoyed the workshop and thank you for coming.  Hopefully we will be able to reuse the materials in the future.</p>
<p>I've attached our presentation. <a href="http://blog.scotsts.com/wp-content/uploads/2013/05/Conducting-a-DIY-Security-Review-latest.pdf">Conducting a DIY Security Review - latest</a></p>
<p>&nbsp;</p>

    
    
  </div>

</article>

<hr/>

<ul class="pager"> 

  
  <li class="previous">
    
    <a href="/page5">&larr; Newer</a>
    
  </li>
  
  
  <li>
    <span class="page_number">Page: 6 of 51</span>
  </li>

  
  <li class="next">
    <a href="/page7">Older &rarr;</a>
  </li>
  

</ul>




		<footer>
			<hr/>
			<p>
				&copy; 2019 raesene with Jekyll. Theme: <a href="https://github.com/dbtek/dbyll">dbyll</a> by dbtek.
			</p>
		</footer>
	</div>

	<script type="text/javascript" src="/assets/resources/jquery/jquery.min.js"></script>
	<script type="text/javascript" src="/assets/resources/bootstrap/js/bootstrap.min.js"></script>
	<script type="text/javascript" src="/assets/js/app.js"></script>
</body>
</html>


